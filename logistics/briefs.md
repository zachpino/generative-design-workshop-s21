# Designing Contextual Intelligences

###  Generative Design Workshop Final Briefs – Project Description

We have explored many, many generative tools and approaches this semester. Some have long histories and some are very new, but all can be applied in novel spaces today. And in the near, forecasted future — recent advances in data capture and analysis render generative tools not only possible for future design application, but also plausibly deployable in all sort of contexts. So, let's make some cool things with data and algorithms!

-----

### Provocation

Design is often defined by its overwhelming drive to intervene **once**, with maximum impact. Nearly all of our approaches involve finding leverage locations, averages and modes, pressure points, and force multipliers. Let's change that, and instead consider contextual variation, diversity, and statistical extremes using generative tools (such as machine learning, algorthmic recursion, evolutionary modeling, computational form-making, etc...).

Contemporary data-oriented and generative tools allow designers to fundamentally rethink the expected relationship with the **Few:One:Many** approach that has long defined our practice. Teams of a **few designers** produce **one design** for **many, many, many users**. This asymmetry in authorship and impact, though necessary due to contextual pressures and technical feasability, has limited design's view and playground. Generative design approaches jumble that formula up, and enable designers to author unique experiences for every single user by *designing algorithms* capable of producing limitless constellations of potential designs. 

The data-first, unique, dynamic experiences that we have become familiar with in digital entertainment contexts (your Netflix, Spotify, and YouTube playlists, for example) can now be applied off-screen, and mutate into new ground-truth expectations in other areas of design impact such as social, service, product, and regulatory/policy spaces. Many of these benefits can be immediately leveraged within an era of increasing cultural comfort with individualism, inclusivity, and flexible self-definition. Designers have long designed for *markets* and *personas*, but these newly emergent technologies permit the design discipline to instead produce *bespoke* and *contextually-targeted* design interventions for *individuals*.

With these thoughts in your mind, choose a specific focus area below for examination and experimentation. Through the next 8 weeks, we will research and consider how the notated questions and more would be approached from a variety of generative design approaches — and produce a design algorithm empowered with your intelligence of the space that is capable of producing unique outcomes for unique circumstance. Our final algorithm may be small and targeted — a fraction of the imagined potential — but the goal is to produce a representative example of your research and new point of view.

-----

### Choose a Space!
We will break up into several teams (working together or apart) at this point in the semester, and have targeted meetings going forward.

##### Pattern and Palette ((Khroma)[http://khroma.co])
How can generative approaches model the variety of human aesthetic preferences and contextual requirements? How can algorithms encode the tension between our frozen expectations of "looking designed" and the huge number of viable possibilities? How can a computer create more intelligent templates, assets, and tools for designers given their project constraints? What about cultural differences in aesthetic expectation?

##### Body, Garment, and Materiality ([Unyq](http://unyq.com/en-language/home-en/) and [GAMAA](https://gamma.umd.edu/researchdirections/virtualtryon/garmentgeneration/))
How can generative approaches understand the variance and dynamics of the human body? How can we interface with anatomy in an intelligent way, and algorithmically produce bespoke garments? How do *fashion and trend* intertwine with the requirements of each body and the performance needs of the wearer? How can materiality adapt to, and reflect, contextual needs?

##### Language, Alphabets, Poetry, Story ([Sand Glyphs](https://inconvergent.net/generative/sand-glyphs/))
How can generative approaches synthesize aspects of written and spoken narrative and communication? How might generative approaches create dynamic encodings to selectively hide or expose information? How might the strictures of language and narrative be both codified, and also experimented upon? How do meaning and interpretation become reflected in — and accelerated by — these new encodings?

##### Urban Processes ([Delve](https://hello.delve.sidewalklabs.com))
How can generative approaches sensitively analyze and forecast the cost (financial, carbon, supply chain, temporal, inhabitant opportunity, etc...) of various urban processes, and provide meaninful insights and recommendations? What aspects of urban life might be ripe for generative intervention? How can we encode the genome of a city, and how it varies with respect to itself over time, and also other cities? What aspects of city design are flexible, and which are fixed? What data sources are trustworthy and worthy of inclusion, and which might need to be modulated or discarded? 

-----
 
### Process
- How do we *encode* examples and the chromosome of the area of research? Remember *parametric rigs*?
- What *algorithmic tools* can we use to mine the examples for overlap and characteristic differences? Explore [Food4Rhino](https://www.food4rhino.com) and all the other resources we've looked at.
- What will our algorithmic intelligence need to *generate*?

Through all these: Be weird. Do weird stuff. Make weird things. 

-----

### Deliverables

- Produce **three** representative outputs of your generative understanding — in image, or fabricated by hand or machine.

- Illustrated key to reading your outputs and how they encode your algorithmic understanding, designed for a 5"x7" post card, double-sided (one side featuring renders or photos), styled in combination with your outputs.

- Annotated Grasshopper, Rhino, or other design files.

- 250-500 word description of your project, and how your algorithmic intelligence makes decisions.
